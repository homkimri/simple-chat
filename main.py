import streamlit as st
from langchain.memory import ConversationBufferMemory
from untils import get_chat_response

st.title("ğŸ’¬ç®€æ˜“èŠå¤©åŠ©æ‰‹")
options = ['deepseek-chat', 'deepseek-reasoner']
# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(return_messages=True)
    st.session_state["messages"] = [{"role": "ai",
                                     "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€ä¸ªèŠå¤©åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"}]
# ä¾§è¾¹æ è®¾ç½®
with st.sidebar:
    model = st.selectbox("é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹", options)
    openai_api_key = st.text_input("deepseek APIå¯†é’¥", type="password")
    st.markdown("[è·å–deepseek APIå¯†é’¥](https://platform.deepseek.com/)")
    if st.button("åˆ›å»ºæ–°å¯¹è¯"):
        st.session_state["memory"] = ConversationBufferMemory(return_messages=True)  # é‡ç½®è®°å¿†
        st.session_state["messages"] = [
            {"role": "ai", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€ä¸ªèŠå¤©åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"}]  # é‡ç½®èŠå¤©è®°å½•
        st.rerun()  # é‡æ–°è¿è¡Œåº”ç”¨ä»¥æ›´æ–°ç•Œé¢

# æ˜¾ç¤ºèŠå¤©è®°å½•
for message in st.session_state["messages"]:
    st.chat_message(message["role"]).write(message["content"])

# ç”¨æˆ·è¾“å…¥å¤„ç†
prompt = st.chat_input("è¯·è¾“å…¥é—®é¢˜")
if prompt:
    if not openai_api_key:
        st.info("è¯·è¾“å…¥æ‚¨çš„é€šä¹‰åƒé—®API Key")
        st.stop()
    st.session_state["messages"].append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)

    with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
        response = get_chat_response(prompt, st.session_state["memory"], openai_api_key, model)
        msg = {"role": "ai","content": response}
        st.session_state["messages"].append(msg)
        st.chat_message("ai").write(response)